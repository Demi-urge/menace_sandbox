# CompositeWorkflowScorer

`CompositeWorkflowScorer` runs workflows under simulated environments and aggregates ROI metrics. It wraps `ROITracker` and persists results in `roi_results.db` via `ROIResultsDB`.

## ROI profile configuration

`CompositeWorkflowScorer` initialises an `ROICalculator` which expects ROI
profiles in `configs/roi_profiles.yaml`. If this configuration file is missing
or invalid, a `RuntimeError` is raised. Tests or lightweight setups can inject a
minimal calculator by providing the `calculator_factory` parameter:

```python
from types import SimpleNamespace
from menace_sandbox.composite_workflow_scorer import CompositeWorkflowScorer

def stub_calculator():
    return SimpleNamespace(
        calculate=lambda metrics, _p: (sum(metrics.values()), False, []),
        profiles={"default": {}},
    )

scorer = CompositeWorkflowScorer(calculator_factory=stub_calculator)
```

## API overview

```python
from menace_sandbox.composite_workflow_scorer import CompositeWorkflowScorer
from vector_service.context_builder import ContextBuilder

scorer = CompositeWorkflowScorer()
builder = ContextBuilder()
result = scorer.evaluate("wf_example", context_builder=builder)
print(result.success_rate, result.roi_gain)
```

`evaluate` refreshes the builder's database weights before running the
simulations to ensure the latest ranking information is applied.

## Metric formulas

- **Workflow synergy** – ratio of summed individual module ROI gains to the combined ROI gain:

  ```
  workflow_synergy_score = sum(roi_gain_m for m in modules) / total_roi_gain
  ```

- **Bottleneck index** – slowest module runtime divided by total workflow runtime:

  ```
  bottleneck_index = max(runtime_m) / sum(runtime_m for m in modules)
  ```

- **Patchability** – derivative of the ROI trend over recent runs normalised by
  recent volatility and scaled by the patch success rate:

  ```
  patchability_score = slope(recent_roi_history) / std(recent_roi_history) * patch_success_rate
  ```

The metric helper functions above reside in `workflow_scorer_core` and are
re-exported by this module for convenience.

## Database schema

`ROIResultsDB` creates a local SQLite table `workflow_results`:

| column | type | description |
| --- | --- | --- |
| `workflow_id` | TEXT | identifier of the evaluated workflow |
| `run_id` | TEXT | unique identifier for this evaluation run |
| `timestamp` | TEXT | insertion timestamp |
| `runtime` | REAL | total execution time in seconds |
| `success_rate` | REAL | successes divided by total module runs |
| `roi_gain` | REAL | sum of `roi_history` deltas |
| `workflow_synergy_score` | REAL | summed module ROI gains divided by combined gain |
| `bottleneck_index` | REAL | max module runtime divided by total runtime |
| `patchability_score` | REAL | ROI slope normalised by volatility and scaled by patch success rate |
| `module_deltas` | TEXT | JSON mapping `module -> {success_rate, roi_delta}` |

## CLI example

Run a workflow evaluation and fetch stored results:

```bash
python - <<'PY'
from menace_sandbox.composite_workflow_scorer import CompositeWorkflowScorer
from menace_sandbox.roi_results_db import module_impact_report
from vector_service.context_builder import ContextBuilder

scorer = CompositeWorkflowScorer()
builder = ContextBuilder()
res = scorer.evaluate("wf_example", context_builder=builder)
cur = scorer.results_db.conn.cursor()
run_id = cur.execute(
    "SELECT run_id FROM workflow_results WHERE workflow_id=? ORDER BY timestamp DESC LIMIT 1",
    ("wf_example",),
).fetchone()[0]
print(module_impact_report("wf_example", run_id, scorer.results_db.path))
PY
```

This snippet runs the workflow, stores metrics in `roi_results.db`, and prints a module impact report for the most recent run.

## Trend analysis

Repeated evaluations of the same workflow can be visualised by querying the
stored trend metrics:

```python
from menace_sandbox.roi_results_db import ROIResultsDB, compute_rolling_metrics

db = ROIResultsDB("roi_results.db")
trends = db.fetch_trends("wf_example")
enriched = compute_rolling_metrics(trends, window=3)
for point in enriched:
    print(point["timestamp"], point["roi_gain"], point["roi_gain_avg"], point["roi_gain_slope"])
```

`fetch_trends` returns the raw ROI gain, synergy, bottleneck and patchability
metrics ordered by evaluation time. `compute_rolling_metrics` augments the data
with rolling averages and slope values suitable for plotting.

## Workflow evolution

`CompositeWorkflowScorer` powers the benchmarking step of
`WorkflowEvolutionManager`. The manager scores the baseline workflow and each
variant generated by `WorkflowEvolutionBot.generate_variants(limit)` and
promotes the highest‑ROI sequence. The `limit` argument bounds the number of
candidates while `ROI_GATING_THRESHOLD` and `ROI_GATING_CONSECUTIVE` gate
further evolution once improvements flatten out.

Example:

```python
from menace_sandbox.self_improvement import (
    SelfImprovementEngine,
    ImprovementEngineRegistry,
)

engine = SelfImprovementEngine(bot_name="alpha")
registry = ImprovementEngineRegistry()
registry.register_engine("alpha", engine)
result = registry.run_all_cycles()
print(result["alpha"].workflow_evolution)
```

Calling `run_all_cycles()` evaluates variants with `CompositeWorkflowScorer`
and returns a `workflow_evolution` summary describing any promotion or stability
decision.
